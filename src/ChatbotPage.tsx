// src/ChatbotPage.tsx
import React, { useState, useRef, useEffect, useCallback } from 'react';
// Ensure Message, GeminiModel, SpeechLanguage, and Persona are exported from App.tsx
import { Message, GeminiModel, SpeechLanguage, Persona } from './App';
import ReactMarkdown from 'react-markdown';
import remarkGfm from 'remark-gfm';

// Define the Worker URL - Make sure this is correct
const WORKER_URL = 'https://project-theraphy-ai-proxy.luckgun99.workers.dev/';

// Helper type for history formatting
type HistoryItem = {
Â  sender: 'user' | 'bot';
Â  text: string;
}

// --- Helper Functions ---

// Reads file as Base64
function readFileAsBase64(file: File): Promise<string> {
Â  Â  return new Promise((resolve, reject) => {
Â  Â  Â  Â  const reader = new FileReader();
Â  Â  Â  Â  reader.onload = () => { resolve(reader.result as string); };
Â  Â  Â  Â  reader.onerror = (error) => { reject(error); };
Â  Â  Â  Â  reader.readAsDataURL(file);
Â  Â  });
}

// Calls the Cloudflare Worker (Handles History, Image Response, and Persona)
async function getBotResponse(
Â  Â  userInput: string,
Â  Â  imageData: { type: string; dataUrl: string } | null,
Â  Â  history: HistoryItem[],
Â  Â  model: GeminiModel,
    persona: Persona, // Added persona
Â  Â  accessKey: string
): Promise<{ text: string; imageUrl: string | null }> {
Â  Â  const promptToSend = userInput || (imageData ? "Describe this image." : "");
Â  Â  if (!promptToSend && !imageData) {
Â  Â  Â  Â  return { text: "Please type a message or upload an image.", imageUrl: null };
Â  Â  }

Â  Â  const requestBody: {
Â  Â  Â  Â  prompt: string;
        model: GeminiModel;
        persona: Persona; // Added persona
        imageMimeType?: string;
        imageDataUrl?: string;
Â  Â  Â  Â  accessKey?: string;
        history?: HistoryItem[];
Â  Â  } = {
        prompt: promptToSend,
        model: model,
        persona: persona, // Added persona
        accessKey: accessKey,
        history: history
    };

Â  Â  if (imageData) {
Â  Â  Â  Â  requestBody.imageMimeType = imageData.type;
Â  Â  Â  Â  requestBody.imageDataUrl = imageData.dataUrl;
Â  Â  }

Â  Â  console.log(`Sending Chat Request to Worker (Model: ${model}, Persona: ${persona}, History: ${history.length})`);

Â  Â  try {
Â  Â  Â  Â  const response = await fetch(WORKER_URL, {
Â  Â  Â  Â  Â  Â  method: 'POST',
Â  Â  Â  Â  Â  Â  headers: { 'Content-Type': 'application/json', },
Â  Â  Â  Â  Â  Â  body: JSON.stringify(requestBody),
Â  Â  Â  Â  });

Â  Â  Â  Â  if (!response.ok) {
Â  Â  Â  Â  Â  Â  const errorData = await response.json().catch(() => ({ error: `HTTP error! Status: ${response.status}` }));
Â  Â  Â  Â  Â  Â  throw new Error(errorData?.error || `HTTP error! Status: ${response.status} ${response.statusText}`);
Â  Â  Â  Â  }

Â  Â  Â  Â  const data = await response.json(); // Expects { reply: string, imageUrl?: string | null }
Â  Â  Â  Â  if (data.error) { throw new Error(data.error); }

Â  Â  Â  Â  console.log('Received reply object from Worker:', data);
Â  Â  Â  Â  // Return object, ensuring imageUrl is explicitly null if missing/falsy
Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  text: data.reply || 'Sorry, I received an empty reply.',
Â  Â  Â  Â  Â  Â  imageUrl: data.imageUrl || null
Â  Â  Â  Â  };

Â  Â  } catch (error) {
Â  Â  Â  Â  console.error('Error fetching bot response:', error);
Â  Â  Â  Â  const errorMsg = error instanceof Error ? `Error: ${error.message}` : 'Error: Could not fetch response.';
Â  Â  Â  Â  return { text: errorMsg, imageUrl: null }; // Return object structure on error
Â  Â  }
}

// Parses suggestions like [Suggestion: Text] from text
function parseSuggestions(text: string): { mainText: string; suggestions: string[] } {
Â  Â  const suggestions: string[] = [];
Â  Â  const regex = /\[Suggestion:\s*([^\]]+?)\]/g;
Â  Â  // Replace matches and collect suggestions
Â  Â  const mainText = text.replace(regex, (_match, suggestionText) => {
Â  Â  Â  Â  if (typeof suggestionText === 'string') {
Â  Â  Â  Â  Â  Â  suggestions.push(suggestionText.trim());
Â  Â  Â  Â  }
Â  Â  Â  Â  return ''; // Remove the tag from the main text
Â  Â  }).trim();
Â  Â  return { mainText, suggestions };
}

// Formats timestamp e.g., "16:37"
function formatTime(timestamp: number): string {
Â  Â  if (!timestamp || typeof timestamp !== 'number') return '';
Â  Â  try {
Â  Â  Â  const date = new Date(timestamp);
Â  Â  Â  return date.toLocaleTimeString(navigator.language || 'en-US', {
Â  Â  Â  Â  Â  hour: '2-digit',
Â  Â  Â  Â  Â  minute: '2-digit',
Â  Â  Â  Â  Â  hour12: false // Use 24-hour format
Â  Â  Â  });
Â  Â  } catch (e) {
Â  Â  Â  console.error("Error formatting time:", e);
Â  Â  Â  return '';
Â  Â  }
}

// --- Speech Recognition Setup ---
const SpeechRecognitionImpl = window.SpeechRecognition || window.webkitSpeechRecognition;
const recognitionAvailable = !!SpeechRecognitionImpl;


// --- Component Definition ---
interface ChatbotPageProps {
Â  messages: Message[];
Â  setMessages: React.Dispatch<React.SetStateAction<Message[]>>;
Â  selectedModel: GeminiModel;
Â  sttLang: SpeechLanguage;
  selectedPersona: Persona; // Receive selected persona
Â  accessKey: string;
}

const SEND_COOLDOWN_MS = 3000; // 3 seconds

function ChatbotPage({
    messages,
    setMessages,
    selectedModel,
    sttLang,
    selectedPersona, // Use selected persona
    accessKey
}: ChatbotPageProps) {
Â  // --- State ---
Â  const [input, setInput] = useState<string>('');
Â  const [isLoading, setIsLoading] = useState<boolean>(false);
Â  const [selectedImage, setSelectedImage] = useState<File | null>(null);
Â  const [imagePreviewUrl, setImagePreviewUrl] = useState<string | null>(null);
Â  const [isOnCooldown, setIsOnCooldown] = useState<boolean>(false);
Â  const [isRecording, setIsRecording] = useState<boolean>(false);

Â  // --- Refs ---
Â  const cooldownTimerRef = useRef<NodeJS.Timeout | null>(null);
Â  const recognitionRef = useRef<SpeechRecognition | null>(null);
Â  const messagesEndRef = useRef<HTMLDivElement>(null);
Â  const fileInputRef = useRef<HTMLInputElement>(null);

Â  // --- Effects ---
Â  // Auto-scroll effect
Â  const scrollToBottom = useCallback(() => {
Â  Â  Â  messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
Â  }, []);
Â  useEffect(() => {
Â  Â  Â  const timer = setTimeout(scrollToBottom, 100); // Timeout helps ensure DOM is updated
Â  Â  Â  return () => clearTimeout(timer);
Â  }, [messages, scrollToBottom]);

Â  // Image preview URL cleanup effect
Â  useEffect(() => {
Â  Â  Â  return () => { if (imagePreviewUrl) { URL.revokeObjectURL(imagePreviewUrl); } };
Â  }, [imagePreviewUrl]);

Â  // Cooldown timer cleanup effect
Â  useEffect(() => {
Â  Â  Â  return () => { if (cooldownTimerRef.current) { clearTimeout(cooldownTimerRef.current); } };
Â  }, []);

Â  // Speech recognition initialization effect
Â  useEffect(() => {
Â  Â  Â  if (!recognitionAvailable) { console.warn("Speech Recognition not available."); return; }
Â  Â  Â  if (!recognitionRef.current) {
Â  Â  Â  Â  Â  try {
Â  Â  Â  Â  Â  Â  Â  recognitionRef.current = new SpeechRecognitionImpl();
Â  Â  Â  Â  Â  Â  Â  if (!recognitionRef.current) return;

Â  Â  Â  Â  Â  Â  Â  recognitionRef.current.continuous = false;
Â  Â  Â  Â  Â  Â  Â  recognitionRef.current.interimResults = false;

Â  Â  Â  Â  Â  Â  Â  recognitionRef.current.onresult = (event: SpeechRecognitionEvent) => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  const transcript = event.results[event.results.length - 1]?.[0]?.transcript;
Â  Â  Â  Â  Â  Â  Â  Â  Â  if (transcript) { setInput(transcript); }
Â  Â  Â  Â  Â  Â  Â  Â  Â  setIsRecording(false);
Â  Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  Â  Â  recognitionRef.current.onerror = (event: SpeechRecognitionErrorEvent) => {
Â  Â  Â  Â  Â  Â  Â  Â  Â  console.error('Speech recognition error:', event.error, event.message);
Â  Â  Â  Â  Â  Â  Â  Â  Â  alert(`Speech error: ${event.error} - ${event.message || 'Unknown error'}`);
Â  Â  Â  Â  Â  Â  Â  Â  Â  setIsRecording(false);
Â  Â  Â  Â  Â  Â  Â  };
Â  Â  Â  Â  Â  Â  Â  recognitionRef.current.onstart = () => { setIsRecording(true); };
Â  Â  Â  Â  Â  Â  Â  recognitionRef.current.onend = () => { setIsRecording(false); };

Â  Â  Â  Â  Â  } catch (error) { console.error("Failed to initialize SpeechRecognition:", error); }
Â  Â  Â  }
Â  Â  Â  return () => { if (recognitionRef.current) { try { recognitionRef.current.abort(); } catch(e){ /* ignore */ } } };
Â  }, []); // Empty dependency array


Â  // --- Core Send Logic ---
Â  const sendMessage = useCallback(async (messageText: string, imageFile: File | null) => {
Â  Â  const textTrimmed = messageText.trim();
Â  Â  if ((!textTrimmed && !imageFile) || isLoading || isOnCooldown) return;

Â  Â  const currentTime = Date.now();
Â  Â  const imageToSend = imageFile;
Â  Â  let imageDataForApi: { type: string; dataUrl: string } | null = null;

Â  Â  // --- Prepare History ---
Â  Â  const MAX_HISTORY_MESSAGES = 30;
Â  Â  const relevantHistory = messages
Â  Â  Â  Â  .filter(msg => (msg.sender === 'user' || msg.sender === 'bot') && msg.text) // Ensure text exists
Â  Â  Â  Â  .slice(-MAX_HISTORY_MESSAGES);

Â  Â  const historyToSend: HistoryItem[] = relevantHistory.map(msg => ({
Â  Â  Â  Â  sender: msg.sender as 'user' | 'bot',
Â  Â  Â  Â  text: msg.text
Â  Â  }));

Â  Â  // Create and add the user's message
Â  Â  const newUserMessage: Message = {
Â  Â  Â  id: currentTime,
Â  Â  Â  text: textTrimmed + (imageToSend ? ' (+image)' : ''),
Â  Â  Â  sender: 'user',
Â  Â  Â  timestamp: currentTime,
Â  Â  Â  imageUrl: undefined
Â  Â  };
Â  Â  setMessages((prevMessages) => [...prevMessages, newUserMessage]);

Â  Â  // --- Clear relevant state after adding user message ---
Â  Â  if (imageToSend && imageToSend === selectedImage) {
Â  Â  Â  Â  setSelectedImage(null);
Â  Â  Â  Â  setImagePreviewUrl(null);
Â  Â  Â  Â  if (fileInputRef.current) fileInputRef.current.value = "";
Â  Â  }
Â  Â  if (messageText === input) {
Â  Â  Â  Â  setInput('');
Â  Â  }

Â  Â  // --- Set loading/cooldown state ---
Â  Â  setIsLoading(true);
Â  Â  setIsOnCooldown(true);
Â  Â  if (cooldownTimerRef.current) clearTimeout(cooldownTimerRef.current);
Â  Â  cooldownTimerRef.current = setTimeout(() => { setIsOnCooldown(false); }, SEND_COOLDOWN_MS);

Â  Â  // --- Add visual loading indicator ---
Â  Â  const loadingTime = Date.now() + 1;
Â  Â  setMessages((prevMessages) => [...prevMessages, { id: loadingTime, text: 'Bot is typing...', sender: 'loading', timestamp: loadingTime }]);

Â  Â  // --- Process image if sending one ---
Â  Â  if (imageToSend) {
Â  Â  Â  try {
Â  Â  Â  Â  const base64String = await readFileAsBase64(imageToSend);
Â  Â  Â  Â  imageDataForApi = { type: imageToSend.type, dataUrl: base64String };
Â  Â  Â  } catch (error) {
Â  Â  Â  Â  console.error("Error reading image file:", error);
Â  Â  Â  Â  const errorTime = Date.now() + 2;
Â  Â  Â  Â  setMessages((prevMessages) => [ ...prevMessages.filter(msg => msg.sender !== 'loading'), { id: errorTime, text: "Error reading image file.", sender: 'bot', timestamp: errorTime }]);
Â  Â  Â  Â  setIsLoading(false); setIsOnCooldown(false);
Â  Â  Â  Â  if(cooldownTimerRef.current){ clearTimeout(cooldownTimerRef.current); }
Â  Â  Â  Â  return;
Â  Â  Â  }
Â  Â  }

Â  Â  // --- Get bot response ---
Â  Â  let botResponse: { text: string; imageUrl: string | null } = { text: '', imageUrl: null };
Â  Â  try {
Â  Â  Â  // Pass selectedPersona to the API call function
Â  Â  Â  botResponse = await getBotResponse(
          textTrimmed,
          imageDataForApi,
          historyToSend,
          selectedModel,
          selectedPersona, // Pass persona
          accessKey
      );
Â  Â  } catch (error) {
Â  Â  Â  console.error("Error occurred during getBotResponse call:", error);
Â  Â  Â  const errorMsg = error instanceof Error ? `Error: ${error.message}` : "An unknown error occurred.";
Â  Â  Â  botResponse = { text: errorMsg, imageUrl: null };
Â  Â  } finally {
Â  Â  Â  const botTime = Date.now() + 2;
Â  Â  Â  const newBotMessage: Message = {
Â  Â  Â  Â  Â  id: botTime,
Â  Â  Â  Â  Â  text: botResponse.text,
Â  Â  Â  Â  Â  sender: 'bot',
Â  Â  Â  Â  Â  timestamp: botTime,
Â  Â  Â  Â  Â  imageUrl: botResponse.imageUrl ?? undefined
Â  Â  Â  };
Â  Â  Â  setMessages((prevMessages) => [
Â  Â  Â  Â  ...prevMessages.filter(msg => msg.sender !== 'loading'),
Â  Â  Â  Â  newBotMessage
Â  Â  Â  ]);
Â  Â  Â  setIsLoading(false);
Â  Â  }
Â  // Add selectedPersona to dependency array
Â  }, [messages, isLoading, isOnCooldown, input, selectedImage, setMessages, selectedModel, selectedPersona, accessKey]);


Â  // --- Event Handlers ---
Â  const handleSend = () => { sendMessage(input, selectedImage); }
Â  const handleSuggestionClick = useCallback((suggestionText: string) => {
Â  Â  Â  sendMessage(suggestionText, null); // Pass null for imageFile
Â  }, [sendMessage]); // Depends only on sendMessage
Â  const handleInputChange = (event: React.ChangeEvent<HTMLInputElement>) => { setInput(event.target.value); };
Â  const handleKeyPress = (event: React.KeyboardEvent) => { if (event.key === 'Enter' && !event.shiftKey) { event.preventDefault(); handleSend(); } };
Â  const handleImageChange = (event: React.ChangeEvent<HTMLInputElement>) => {
Â  Â  Â  const file = event.target.files?.[0];
Â  Â  Â  if (file && file.type.startsWith('image/')) {
Â  Â  Â  Â  Â  setSelectedImage(file);
Â  Â  Â  Â  Â  if (imagePreviewUrl) URL.revokeObjectURL(imagePreviewUrl);
Â  Â  Â  Â  Â  setImagePreviewUrl(URL.createObjectURL(file));
Â  Â  Â  } else {
Â  Â  Â  Â  Â  setSelectedImage(null);
Â  Â  Â  Â  Â  setImagePreviewUrl(null);
Â  Â  Â  Â  Â  if (file) alert("Please select a valid image file (PNG, JPG, GIF, WEBP).");
Â  Â  Â  Â  Â  if (fileInputRef.current) fileInputRef.current.value = "";
Â  Â  Â  }
Â  };
Â  const handleImageUploadClick = () => { fileInputRef.current?.click(); };
Â  const removeSelectedImage = () => {
Â  Â  Â  setSelectedImage(null);
Â  Â  Â  setImagePreviewUrl(null);
Â  Â  Â  if (fileInputRef.current) fileInputRef.current.value = "";
Â  }
Â  const handleMicClick = () => {
Â  Â  Â  if (!recognitionRef.current || !recognitionAvailable) { return alert("Speech recognition not initialized or not available."); }
Â  Â  Â  if (isLoading || isOnCooldown || isRecording) {
Â  Â  Â  Â  Â  if (isRecording) {
Â  Â  Â  Â  Â  Â  Â  try { recognitionRef.current.stop(); } catch(e){ console.warn("Error stopping speech recognition", e); setIsRecording(false); }
Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  return;
Â  Â  Â  }
Â  Â  Â  try {
Â  Â  Â  Â  Â  recognitionRef.current.lang = sttLang; // Set language from state
Â  Â  Â  Â  Â  recognitionRef.current.start();
Â  Â  Â  Â  Â  setIsRecording(true);
Â  Â  Â  } catch (e) {
Â  Â  Â  Â  Â  console.error("Error starting speech recognition:", e);
Â  Â  Â  Â  Â  alert("Could not start recognition. Please check microphone permissions.");
Â  Â  Â  Â  Â  setIsRecording(false);
Â  Â  Â  }
Â  };


Â  // --- JSX Rendering ---
Â  return (
Â  Â  Â  Â <div className="chatbot-container">
Â  Â  Â  Â  Â {/* Messages Area */}
Â  Â  Â  Â  Â <div className="chatbot-messages">
Â  Â  Â  Â  Â  Â {messages.map((message: Message) => {
Â  Â  Â  Â  Â  Â  Â  Â let mainText = message.text;
Â  Â  Â  Â  Â  Â  Â  Â let suggestions: string[] = [];
Â  Â  Â  Â  Â  Â  Â  Â if (message.sender === 'bot' && mainText && !mainText.startsWith('Error:')) {
Â  Â  Â  Â  Â  Â  Â  Â  Â const parsed = parseSuggestions(mainText);
Â  Â  Â  Â  Â  Â  Â  Â  Â mainText = parsed.mainText;
Â  Â  Â  Â  Â  Â  Â  Â  Â suggestions = parsed.suggestions;
Â  Â  Â  Â  Â  Â  Â  Â }

Â  Â  Â  Â  Â  Â  Â  Â return (
Â  Â  Â  Â  Â  Â  Â  Â  Â <div key={message.id} className={`message-wrapper message-wrapper-${message.sender}`}>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â <div className={`message ${message.sender}`}>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â {/* Bot Message Content */}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â {message.sender === 'bot' ? (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {/* Render Text */}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {mainText && mainText.trim() !== '' && !mainText.startsWith('Error:') && (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â <ReactMarkdown remarkPlugins={[remarkGfm]} children={mainText}/>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {/* Render Image */}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {message.imageUrl && (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  <img src={message.imageUrl} alt="Bot response" style={{ maxWidth: '100%', maxHeight: '350px', display: 'block', marginTop: mainText && mainText.trim() !== '' ? '8px' : '0px', borderRadius: '8px', cursor:'pointer' }} onClick={() => window.open(message.imageUrl, '_blank')} onError={(e) => { e.currentTarget.style.display = 'none'; }} />
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )}
                           {/* Handle empty valid response */}
                           {!(mainText && mainText.trim() !== '') && !message.imageUrl && !(message.text && message.text.startsWith('Error:')) && ( <i>[Empty response]</i> )}
                           {/* Display errors */}
                           {message.text && message.text.startsWith('Error:') && ( <p style={{color: 'var(--remove-button-bg, red)'}}>{message.text}</p> )}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  </>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â ) : message.sender === 'loading' ? (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â <i>{message.text}</i> // Loading Indicator
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â ) : (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â <p>{message.text}</p> // User Message
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â )}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â </div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â {/* Timestamp */}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â {message.sender !== 'loading' && message.timestamp && (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â <span className="message-timestamp">{formatTime(message.timestamp)}</span>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â )}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â {/* Suggestions */}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â {suggestions.length > 0 && (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â <div className="suggestions-container">
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â {suggestions.map((suggestion, index) => (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â <button key={index} className="suggestion-button" onClick={() => handleSuggestionClick(suggestion)} disabled={isLoading || isOnCooldown}>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  {suggestion}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â </button>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â ))}
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â </div>
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â )}
Â  Â  Â  Â  Â  Â  Â  Â  Â </div>
Â  Â  Â  Â  Â  Â  Â  Â );
Â  Â  Â  Â  Â  Â })}
Â  Â  Â  Â  Â  Â  <div ref={messagesEndRef} /> {/* For scrolling */}
Â  Â  Â  Â  Â </div>

Â  Â  Â  Â  Â {/* Image Preview Area */}
Â  Â  Â  Â  Â {imagePreviewUrl && (
Â  Â  Â  Â  Â  Â <div className="image-preview-area">
Â  Â  Â  Â  Â  Â  Â <img src={imagePreviewUrl} alt="Preview" style={{maxHeight: '50px', maxWidth: '50px', objectFit: 'cover', marginRight: '10px', borderRadius: '4px'}} />
Â  Â  Â  Â  Â  Â  Â <button onClick={removeSelectedImage} title="Remove image" className="remove-image-button">X</button>
Â  Â  Â  Â  Â  Â </div>
Â  Â  Â  Â  Â )}

Â  Â  Â  Â  Â {/* Input Area */}
Â  Â  Â  Â  Â <div className="chatbot-input-area">
Â  Â  Â  Â  Â  Â  <input type="file" ref={fileInputRef} onChange={handleImageChange} accept="image/png, image/jpeg, image/gif, image/webp" style={{ display: 'none' }} />
Â  Â  Â  Â  Â  Â  <button onClick={handleImageUploadClick} className="upload-button" title="Upload Image" disabled={isLoading || isOnCooldown}>ğŸ“</button>
Â  Â  Â  Â  Â  Â  <input type="text" value={input} onChange={handleInputChange} onKeyPress={handleKeyPress} placeholder="Type message or speak..." disabled={isLoading || isOnCooldown}/>
Â  Â  Â  Â  Â  Â  {recognitionAvailable && (
Â  Â  Â  Â  Â  Â  Â  <button onClick={handleMicClick} className={`mic-button ${isRecording ? 'recording' : ''}`} title={isRecording ? "Stop Recording" : `Start Recording (${sttLang})`} disabled={isLoading || isOnCooldown}>
Â  Â  Â  Â  Â  Â  Â  Â  {isRecording ? 'â– ' : 'ğŸ™ï¸'}
Â  Â  Â  Â  Â  Â  Â  </button>
Â  Â  Â  Â  Â  Â  )}
Â  Â  Â  Â  Â  Â  <button onClick={handleSend} disabled={isLoading || isOnCooldown || (!input.trim() && !selectedImage)} title="Send">
Â  Â  Â  Â  Â  Â  Â  Â <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" width="1.2em" height="1.2em"><path d="M3.478 2.405a.75.75 0 00-.926.94l2.432 7.905H13.5a.75.75 0 010 1.5H4.984l-2.432 7.905a.75.75 0 00.926.94 60.519 60.519 0 0018.445-8.986.75.75 0 000-1.218A60.517 60.517 0 003.478 2.405z" /></svg>
Â  Â  Â  Â  Â  Â  </button>
Â  Â  Â  Â  Â </div>
Â  Â  Â  Â </div>
Â  Â );
}

export default ChatbotPage;